# Green Agent Benchmark - å®Œæ•´ä½¿ç”¨æŒ‡å—

è¿™æ˜¯Green Agent Benchmarké¡¹ç›®çš„å®Œæ•´ä½¿ç”¨è¯´æ˜æ–‡æ¡£ï¼Œæ¶µç›–å®‰è£…ã€é…ç½®ã€è¿è¡Œå®éªŒå’ŒæŸ¥çœ‹ç»“æœçš„å…¨æµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
4. [è¿è¡Œå®éªŒ](#è¿è¡Œå®éªŒ)
5. [é…ç½®æ–‡ä»¶è¯¦è§£](#é…ç½®æ–‡ä»¶è¯¦è§£)
6. [ä»£ç†å¼€å‘](#ä»£ç†å¼€å‘)
7. [æ’è¡Œæ¦œç³»ç»Ÿ](#æ’è¡Œæ¦œç³»ç»Ÿ)
8. [æ•°æ®åˆ†æ](#æ•°æ®åˆ†æ)
9. [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
10. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

Green Agent Benchmarkæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒåŸºäºè§„åˆ™çš„æ‰‘å…‹ä»£ç†çš„å®æ—¶No-Limit Texas Hold'emè¯„ä¼°æ¡†æ¶ã€‚è¯¥é¡¹ç›®æä¾›ï¼š

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **NLHEæ¸¸æˆå¼•æ“**: å®Œæ•´çš„å¾·å·æ‰‘å…‹çŠ¶æ€æœºï¼Œæ”¯æŒç›²æ³¨ã€è¾¹æ± ã€å…¨æŠ¼é”å®š
- **åŒæ¨¡å¼è¯„ä¼°**: Heads-Up (HU)å’Œ6-Maxä¸¤ç§æ¸¸æˆæ¨¡å¼
- **æ–¹å·®æ§åˆ¶**: Duplicate-HUåŒ¹é…å’Œä½ç½®å¹³è¡¡å‰¯æœ¬æŠ€æœ¯
- **å¤šä»£ç†æ”¯æŒ**: æ”¯æŒLLMã€è§„åˆ™å‹ã€å¼ºåŒ–å­¦ä¹ ç­‰å¤šç§ç±»å‹ä»£ç†
- **ç»Ÿè®¡æŒ‡æ ‡**: bb/100ã€ç½®ä¿¡åŒºé—´ã€è¡Œä¸ºç»Ÿè®¡ï¼ˆVPIP/PFR/AFç­‰ï¼‰
- **Webæ’è¡Œæ¦œ**: å®æ—¶æ›´æ–°çš„äº¤äº’å¼æ’è¡Œæ¦œç³»ç»Ÿ
- **å®Œå…¨å¯å¤ç°**: åŸºäºç§å­çš„ç¡®å®šæ€§æ—¥å¿—è®°å½•

### ğŸ—ï¸ é¡¹ç›®ç»“æ„
```
Project1_Texas/
â”œâ”€â”€ green_agent_benchmark/    # æ ¸å¿ƒè¯„ä¼°æ¡†æ¶
â”‚   â”œâ”€â”€ engine.py            # å¾·å·æ‰‘å…‹æ¸¸æˆå¼•æ“
â”‚   â”œâ”€â”€ runner.py            # å®éªŒåè°ƒå™¨
â”‚   â”œâ”€â”€ agents/              # å„ç§ä»£ç†å®ç°
â”‚   â”œâ”€â”€ metrics.py           # æŒ‡æ ‡è®¡ç®—
â”‚   â””â”€â”€ cli.py               # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ leaderboard/             # Webæ’è¡Œæ¦œç³»ç»Ÿ
â”œâ”€â”€ configs/                 # å®éªŒé…ç½®æ–‡ä»¶
â”œâ”€â”€ artifacts/               # å®éªŒç»“æœå­˜å‚¨
â”œâ”€â”€ scripts/                 # è¾…åŠ©è„šæœ¬
â””â”€â”€ docs/                    # æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚
- **Python 3.10+**
- **æ“ä½œç³»ç»Ÿ**: macOS/Linux/Windows
- **å†…å­˜**: å»ºè®®8GB+
- **å­˜å‚¨**: è‡³å°‘5GBå¯ç”¨ç©ºé—´

### 2. å®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/lusunjia/Project1_Texas.git
cd Project1_Texas

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# macOS/Linux:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate

# 4. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 5. éªŒè¯å®‰è£…
python -m green_agent_benchmark.cli --help
```

### 3. è¿è¡Œç¬¬ä¸€ä¸ªå®éªŒ

```bash
# è¿è¡Œ10æ‰‹å¿«é€Ÿæµ‹è¯•
python -m green_agent_benchmark.cli \
  --config configs/demo_hu_10hands.yaml \
  --agent baseline:random-hu \
  --output artifacts/first_test
```

### 4. å¯åŠ¨æ’è¡Œæ¦œ

```bash
# ç”Ÿæˆæ’è¡Œæ¦œæ•°æ®
python leaderboard/leaderboard_generator.py

# å¯åŠ¨WebæœåŠ¡å™¨
python leaderboard/server.py
# æµè§ˆå™¨è®¿é—®: http://localhost:8000
```

---

## âš™ï¸ ç¯å¢ƒé…ç½®

### APIå¯†é’¥é…ç½®

åˆ›å»º `.env` æ–‡ä»¶æ¥å­˜å‚¨APIå¯†é’¥ï¼š

```bash
# .env æ–‡ä»¶å†…å®¹
# OpenAI (GPT-5)
OPENAI_API_KEY=sk-your-openai-key

# DeepSeek
DEEPSEEK_API_KEY=your-deepseek-key
DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# Gemini
GEMINI_API_KEY=your-gemini-key
GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta

# Moonshot Kimi
KIMI_API_KEY=your-kimi-key
KIMI_API_BASE=https://api.moonshot.cn/v1

# Alibaba Qwen
QWEN_API_KEY=your-qwen-key
QWEN_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1

# ByteDance Doubao
DOUBAO_API_KEY=your-doubao-key
DOUBAO_API_BASE=https://ark.cn-beijing.volces.com/api/v3
```

### ç¯å¢ƒå˜é‡è¯´æ˜
- `*_API_KEY`: å„å¹³å°çš„APIå¯†é’¥
- `*_API_BASE`: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
- `*_MODEL`: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰

---

## ğŸ® è¿è¡Œå®éªŒ

### HU (Heads-Up) æ¨¡å¼

#### 1. åŸºç¡€HUå®éªŒ
```bash
# Randomä»£ç† vs TAGä»£ç†
python -m green_agent_benchmark.cli \
  --config configs/dev_hu.yaml \
  --agent baseline:random-hu \
  --output artifacts/random_vs_tag
```

#### 2. LLM vs LLMå¯¹æˆ˜
```bash
# GPT-5 vs DeepSeek
export OPENAI_API_KEY=your-key
export DEEPSEEK_API_KEY=your-key

python -m green_agent_benchmark.cli \
  --config configs/demo_hu_deepseek_vs_gpt5.yaml \
  --agent green_agent_benchmark.agents.gpt5_agent:GPT5Agent \
  --agent-name GPT5 \
  --output artifacts/gpt5_vs_deepseek
```

#### 3. è‡ªå®šä¹‰ä»£ç†æµ‹è¯•
```bash
# ä½¿ç”¨è‡ªå·±å¼€å‘çš„ä»£ç†
python -m green_agent_benchmark.cli \
  --config configs/dev_hu.yaml \
  --agent mybot:MyAgent \
  --agent-name "My Custom Agent" \
  --output artifacts/my_agent_test
```

### 6-Max æ¨¡å¼

#### 1. 6-MaxåŸºç¡€æµ‹è¯•
```bash
python -m green_agent_benchmark.cli \
  --config configs/dev_6max.yaml \
  --agent baseline:tag-6 \
  --output artifacts/tag_6max
```

#### 2. LLM Showdown (6ä¸ªLLMåŒå°ç«æŠ€)
```bash
# ç¡®ä¿æ‰€æœ‰APIå¯†é’¥éƒ½å·²é…ç½®
python -m green_agent_benchmark.cli \
  --config configs/sixmax_llm_showdown.yaml \
  --output artifacts/sixmax_showdown
```

### å®éªŒè¾“å‡º

æ¯ä¸ªå®éªŒä¼šåœ¨æŒ‡å®šçš„ `--output` ç›®å½•ç”Ÿæˆï¼š

```
artifacts/experiment_name/
â”œâ”€â”€ logs/                    # è¯¦ç»†æ¸¸æˆæ—¥å¿—
â”‚   â”œâ”€â”€ hu/                  # HUæ¨¡å¼æ—¥å¿—
â”‚   â””â”€â”€ sixmax/              # 6-Maxæ¨¡å¼æ—¥å¿—
â””â”€â”€ metrics/                 # ç»Ÿè®¡æŒ‡æ ‡
    â”œâ”€â”€ metrics.json         # èšåˆç»Ÿè®¡æ•°æ®
    â””â”€â”€ per_hand_metrics.ndjson  # é€æ‰‹è¯¦ç»†æ•°æ®
```

---

## ğŸ“ é…ç½®æ–‡ä»¶è¯¦è§£

### HUé…ç½®ç¤ºä¾‹ (`configs/dev_hu.yaml`)

```yaml
mode: hu                     # æ¸¸æˆæ¨¡å¼: hu æˆ– sixmax
blinds:
  sb: 50                     # å°ç›²æ³¨
  bb: 100                    # å¤§ç›²æ³¨
stacks_bb: 100               # èµ·å§‹ç­¹ç (ä»¥å¤§ç›²æ³¨ä¸ºå•ä½)
seeds: [101, 102, 103]       # éšæœºç§å­åˆ—è¡¨
hands_per_seed: 500          # æ¯ä¸ªç§å­çš„æ‰‹æ•°
replicas: 2                  # å‰¯æœ¬æ•°é‡(HUæ¨¡å¼å¿…é¡»ä¸º2)
opponent_mix:                # å¯¹æ‰‹ç»„åˆ
  random-hu: 0.3             # 30% Randomä»£ç†
  tag-hu: 0.5                # 50% TAGä»£ç†
  cfr-lite-hu: 0.2           # 20% CFR-liteä»£ç†
```

### 6-Maxé…ç½®ç¤ºä¾‹ (`configs/dev_6max.yaml`)

```yaml
mode: sixmax                 # 6-Maxæ¨¡å¼
blinds:
  sb: 50
  bb: 100
stacks_bb: 100
seeds: [201, 202, 203]
hands_per_replica: 200       # æ¯ä¸ªå‰¯æœ¬çš„æ‰‹æ•°
seat_replicas: 6             # åº§ä½å‰¯æœ¬æ•°é‡(å¿…é¡»ä¸º6)
opponent_pool:               # å¯¹æ‰‹æ± 
  random-6: 0.3
  tag-6: 0.4
  cfr-lite-6: 0.3
population_mirroring: true   # ç¾¤ä½“é•œåƒ(ä¿æŒå¯¹æ‰‹ä¸€è‡´æ€§)
```

### å®Œæ•´Lineupé…ç½®

```yaml
mode: sixmax
lineup:                      # ç›´æ¥æŒ‡å®šæ‰€æœ‰6ä¸ªåº§ä½
  - baseline:gpt5-6
  - baseline:deepseek-6
  - baseline:gemini-6
  - baseline:kimi-6
  - baseline:qwen-6
  - baseline:doubao-6
# ä½¿ç”¨lineupæ—¶ä¸éœ€è¦opponent_pool
```

### é«˜çº§å‚æ•°

```yaml
# ç³»ç»Ÿçº§è®¾ç½®
time_per_decision_ms: 60000  # æ¯æ¬¡å†³ç­–æ—¶é—´é™åˆ¶
auto_top_up: true            # è‡ªåŠ¨è¡¥æ»¡ç­¹ç 
system_prompt_override: |    # è¦†ç›–ç³»ç»Ÿæç¤ºè¯
  You are a poker expert...

# å®éªŒæ§åˆ¶
max_illegal_actions: 50      # æœ€å¤§éæ³•åŠ¨ä½œæ•°
max_timeouts: 10             # æœ€å¤§è¶…æ—¶æ¬¡æ•°
```

---

## ğŸ‘¨â€ğŸ’» ä»£ç†å¼€å‘

### åŸºç¡€ä»£ç†æ¥å£

åˆ›å»ºè‡ªå®šä¹‰ä»£ç†éœ€è¦å®ç°ä»¥ä¸‹æ¥å£ï¼š

```python
from green_agent_benchmark.schemas import ActionRequest, ActionResponse

class MyAgent:
    name = "MyCustomAgent"  # ä»£ç†åç§°
    
    def reset(self, seat_id: int, table_config: dict) -> None:
        """æ¯æ‰‹å¼€å§‹å‰çš„é‡ç½®(å¯é€‰)"""
        self.seat_id = seat_id
        self.starting_stack = table_config.get('starting_stack', 10000)
    
    def act(self, request: ActionRequest) -> ActionResponse:
        """æ ¹æ®æ¸¸æˆçŠ¶æ€åšå‡ºå†³ç­–"""
        # è·å–æ¸¸æˆä¿¡æ¯
        hole_cards = request.hole_cards      # åº•ç‰Œ ['As', 'Kd']
        board = request.board                # å…¬å…±ç‰Œ
        pot = request.pot                    # åº•æ± å¤§å°
        to_call = request.to_call           # éœ€è¦è·Ÿæ³¨çš„é‡‘é¢
        legal_actions = request.legal_actions # åˆæ³•åŠ¨ä½œåˆ—è¡¨
        
        # ç®€å•ç­–ç•¥ç¤ºä¾‹
        if "fold" in legal_actions and to_call > 200:
            return ActionResponse(action="fold")
        elif "call" in legal_actions:
            return ActionResponse(action="call")
        elif "check" in legal_actions:
            return ActionResponse(action="check")
        else:
            return ActionResponse(action="fold")
```

### ActionRequest è¯¦ç»†å­—æ®µ

```python
@dataclass
class ActionRequest:
    # åŸºç¡€ä¿¡æ¯
    seat_count: int          # åº§ä½æ•° (2æˆ–6)
    table_id: str           # æ¡Œå­ID
    hand_id: str            # æ‰‹ç‰ŒID
    seat_id: int            # å½“å‰åº§ä½å·
    button_seat: int        # æŒ‰é’®ä½åº§ä½å·
    
    # ç›²æ³¨ä¿¡æ¯
    blinds: dict           # {"sb": 50, "bb": 100}
    stacks: dict           # {seat_id: chips} æ‰€æœ‰ç©å®¶ç­¹ç 
    
    # åº•æ± ä¿¡æ¯
    pot: int               # å½“å‰åº•æ± å¤§å°
    to_call: int           # éœ€è¦è·Ÿæ³¨çš„é‡‘é¢
    min_raise_to: int      # æœ€å°åŠ æ³¨åˆ°å¤šå°‘
    
    # ç‰Œé¢ä¿¡æ¯
    hole_cards: list       # è‡ªå·±çš„åº•ç‰Œ ['As', 'Kd']
    board: list            # å…¬å…±ç‰Œ ['Jh', '9c', '2d']
    
    # åŠ¨ä½œä¿¡æ¯
    action_history: list   # å†å²åŠ¨ä½œè®°å½•
    legal_actions: list    # å½“å‰åˆæ³•åŠ¨ä½œ ['fold', 'call', 'raise_to']
    
    # æ—¶é—´å’Œå…¶ä»–
    timebank_ms: int       # å‰©ä½™æ€è€ƒæ—¶é—´
    rng_tag: str           # éšæœºç§å­æ ‡ç­¾
```

### ActionResponse è¯¦ç»†å­—æ®µ

```python
@dataclass  
class ActionResponse:
    action: str            # åŠ¨ä½œç±»å‹
    amount: Optional[int] = None   # åŠ æ³¨é‡‘é¢(ä»…raise_toéœ€è¦)
    metadata: Optional[dict] = None # é¢å¤–ä¿¡æ¯(å¯é€‰)
```

### åŠ¨ä½œç±»å‹è¯´æ˜

| åŠ¨ä½œ | è¯´æ˜ | ä½•æ—¶å¯ç”¨ | amountå‚æ•° |
|------|------|----------|-----------|
| `fold` | å¼ƒç‰Œ | é¢ä¸´ä¸‹æ³¨æ—¶ | ä¸éœ€è¦ |
| `check` | è¿‡ç‰Œ | æ— äººä¸‹æ³¨æ—¶ | ä¸éœ€è¦ |
| `call` | è·Ÿæ³¨ | é¢ä¸´ä¸‹æ³¨æ—¶ | ä¸éœ€è¦ |
| `raise_to` | åŠ æ³¨åˆ°æŒ‡å®šé‡‘é¢ | æœ‰è¶³å¤Ÿç­¹ç æ—¶ | **å¿…éœ€** |

### é«˜çº§ä»£ç†ç¤ºä¾‹

```python
import random
from green_agent_benchmark.schemas import ActionRequest, ActionResponse

class SmartAgent:
    name = "SmartAgent"
    
    def __init__(self):
        self.hand_count = 0
        self.opponent_stats = {}
    
    def reset(self, seat_id: int, table_config: dict):
        self.seat_id = seat_id
        self.hand_count += 1
    
    def act(self, request: ActionRequest) -> ActionResponse:
        # è®°å½•å¯¹æ‰‹ç»Ÿè®¡
        self._update_opponent_stats(request)
        
        # è®¡ç®—åº•æ± èµ”ç‡
        pot_odds = self._calculate_pot_odds(request)
        
        # ä¼°ç®—æ‰‹ç‰Œå¼ºåº¦
        hand_strength = self._evaluate_hand_strength(
            request.hole_cards, request.board
        )
        
        # å†³ç­–é€»è¾‘
        if hand_strength > 0.8:
            # å¼ºç‰Œï¼šåŠ æ³¨
            if "raise_to" in request.legal_actions:
                raise_size = min(request.pot, request.stacks[self.seat_id])
                return ActionResponse(
                    action="raise_to", 
                    amount=request.to_call + raise_size
                )
            elif "call" in request.legal_actions:
                return ActionResponse(action="call")
        
        elif hand_strength > 0.4 and pot_odds > 0.25:
            # ä¸­ç­‰ç‰Œï¼šæ ¹æ®åº•æ± èµ”ç‡å†³å®š
            if "call" in request.legal_actions:
                return ActionResponse(action="call")
        
        # å¼±ç‰Œæˆ–èµ”ç‡ä¸å¥½ï¼šå¼ƒç‰Œ/è¿‡ç‰Œ
        if "check" in request.legal_actions:
            return ActionResponse(action="check")
        else:
            return ActionResponse(action="fold")
    
    def _calculate_pot_odds(self, request: ActionRequest) -> float:
        """è®¡ç®—åº•æ± èµ”ç‡"""
        if request.to_call == 0:
            return 1.0
        return request.pot / (request.pot + request.to_call)
    
    def _evaluate_hand_strength(self, hole_cards: list, board: list) -> float:
        """ä¼°ç®—æ‰‹ç‰Œå¼ºåº¦(ç®€åŒ–ç‰ˆ)"""
        # è¿™é‡Œå¯ä»¥æ¥å…¥æ›´å¤æ‚çš„equityè®¡ç®—
        # ç®€åŒ–ç¤ºä¾‹ï¼šåŸºäºé«˜ç‰Œ
        card_values = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, 
                      '8': 8, '9': 9, 'T': 10, 'J': 11, 'Q': 12, 'K': 13, 'A': 14}
        
        if not hole_cards:
            return 0.0
            
        max_value = max(card_values.get(card[0], 0) for card in hole_cards)
        return min(max_value / 14.0, 1.0)
    
    def _update_opponent_stats(self, request: ActionRequest):
        """æ›´æ–°å¯¹æ‰‹ç»Ÿè®¡ä¿¡æ¯"""
        # åˆ†æaction_historyæ¥ç»Ÿè®¡å¯¹æ‰‹è¡Œä¸º
        pass
```

### ä»£ç†æµ‹è¯•

```python
# test_my_agent.py
from green_agent_benchmark.runner import BenchmarkRunner, SeriesConfig
from my_agent import SmartAgent

def test_agent():
    config = SeriesConfig.from_file("configs/demo_hu_10hands.yaml")
    runner = BenchmarkRunner(config, "test_output")
    
    result = runner.run(SmartAgent())
    
    # æŸ¥çœ‹ç»“æœ
    print(f"BB/100: {result.metrics['SmartAgent']['bb_per_100']}")
    print(f"VPIP: {result.metrics['SmartAgent']['behavior']['vpip']['rate']}")
    
if __name__ == "__main__":
    test_agent()
```

---

## ğŸ“Š æ’è¡Œæ¦œç³»ç»Ÿ

### è‡ªåŠ¨ç”Ÿæˆæ’è¡Œæ¦œ

```bash
# æ‰«æartifactsç›®å½•å¹¶ç”Ÿæˆæ’è¡Œæ¦œæ•°æ®
python leaderboard/leaderboard_generator.py

# å¯åŠ¨WebæœåŠ¡å™¨
python leaderboard/server.py

# æˆ–ä½¿ç”¨ä¾¿æ·è„šæœ¬
chmod +x start_leaderboard.sh
./start_leaderboard.sh
```

### æ’è¡Œæ¦œæŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | è¯´æ˜ | èŒƒå›´ |
|------|------|------|
| **Composite Rating** | ç»¼åˆè¯„åˆ† | 1000-2500+ |
| **BB/100** | æ¯100æ‰‹èµ¢å–çš„å¤§ç›²æ³¨æ•° | -âˆ to +âˆ |
| **Win Rate** | èƒœç‡ | 0.0-1.0 |
| **VPIP** | è‡ªæ„¿å…¥æ± ç‡ | 0%-100% |
| **PFR** | ç¿»ç‰Œå‰åŠ æ³¨ç‡ | 0%-100% |
| **AF** | æ”»å‡»é¢‘ç‡ | 0-âˆ |
| **WTSD** | æ‘Šç‰Œç‡ | 0%-100% |

### æ’è¡Œæ¦œAPI

æ’è¡Œæ¦œæä¾›REST APIæ¥å£ï¼š

```bash
# è·å–æ’è¡Œæ¦œæ•°æ®
curl http://localhost:8000/api/leaderboard

# åˆ·æ–°æ’è¡Œæ¦œ
curl http://localhost:8000/api/refresh

# è·å–ç‰¹å®šä»£ç†ä¿¡æ¯
curl http://localhost:8000/api/agent/{agent_name}
```

### è‡ªå®šä¹‰æ’è¡Œæ¦œ

ä¿®æ”¹ `leaderboard/leaderboard_generator.py` æ¥è‡ªå®šä¹‰æŒ‡æ ‡è®¡ç®—ï¼š

```python
def calculate_composite_rating(agent_data):
    """è‡ªå®šä¹‰è¯„åˆ†è®¡ç®—"""
    bb_100 = agent_data['weighted_bb_per_100']
    win_rate = agent_data['win_rate'] 
    consistency = agent_data['consistency']
    
    # åŸºç¡€åˆ†æ•°
    base_score = 1500
    
    # BB/100è´¡çŒ® (ä¸»è¦å› ç´ )
    bb_score = bb_100 * 4  # æ¯1 bb/100 = 4åˆ†
    
    # èƒœç‡è´¡çŒ®
    win_score = (win_rate - 0.5) * 200  # 50%åŸºå‡†
    
    # ç¨³å®šæ€§è´¡çŒ®  
    consistency_score = (1 - consistency) * 100
    
    return base_score + bb_score + win_score + consistency_score
```

---

## ğŸ“ˆ æ•°æ®åˆ†æ

### æŸ¥çœ‹å®éªŒç»“æœ

```python
import json
import pandas as pd

# è¯»å–èšåˆæŒ‡æ ‡
with open('artifacts/my_experiment/metrics/metrics.json') as f:
    metrics = json.load(f)

print("æ‰€æœ‰ä»£ç†è¡¨ç°:")
for agent_name, stats in metrics.items():
    bb_100 = stats['bb_per_100']
    ci_low, ci_high = stats['bb_per_100_ci']
    vpip = stats['behavior']['vpip']['rate']
    pfr = stats['behavior']['pfr']['rate']
    
    print(f"{agent_name}:")
    print(f"  BB/100: {bb_100:.2f} [{ci_low:.2f}, {ci_high:.2f}]")
    print(f"  VPIP: {vpip:.1%}, PFR: {pfr:.1%}")

# è¯»å–é€æ‰‹æ•°æ®
df = pd.read_json(
    'artifacts/my_experiment/metrics/per_hand_metrics.ndjson',
    lines=True
)

print(f"\næ€»æ‰‹æ•°: {len(df)}")
print(f"å¹³å‡æ¯æ‰‹èµ¢åˆ©: {df['delta'].mean():.2f} chips")
print(f"æœ€å¤§å•æ‰‹èµ¢åˆ©: {df['delta'].max()} chips")
print(f"æœ€å¤§å•æ‰‹äºæŸ: {df['delta'].min()} chips")
```

### é«˜çº§åˆ†æ

```python
# åˆ†æä¸åŒä½ç½®çš„è¡¨ç°
position_stats = df.groupby('position')['delta'].agg(['mean', 'std', 'count'])
print("æŒ‰ä½ç½®ç»Ÿè®¡:")
print(position_stats)

# åˆ†ææ—¶é—´è¶‹åŠ¿
df['cumulative_bb100'] = (df['delta'].cumsum() / df.index * 100) / 100
print(f"æœ€ç»ˆBB/100: {df['cumulative_bb100'].iloc[-1]:.2f}")

# åˆ†æå¯¹æ‰‹å½±å“
opponent_stats = df.groupby('opponent')['delta'].agg(['mean', 'count'])
print("å¯¹ä¸åŒå¯¹æ‰‹çš„è¡¨ç°:")
print(opponent_stats)
```

### å¯¼å‡ºåˆ†ææŠ¥å‘Š

```python
def generate_report(metrics_file, output_file):
    """ç”ŸæˆHTMLåˆ†ææŠ¥å‘Š"""
    with open(metrics_file) as f:
        metrics = json.load(f)
    
    html = f"""
    <html>
    <head><title>æ‰‘å…‹ä»£ç†åˆ†ææŠ¥å‘Š</title></head>
    <body>
        <h1>å®éªŒç»“æœåˆ†æ</h1>
        <table border="1">
            <tr>
                <th>ä»£ç†</th>
                <th>BB/100</th>
                <th>ç½®ä¿¡åŒºé—´</th>
                <th>VPIP</th>
                <th>PFR</th>
                <th>å†³ç­–æ—¶é—´(ms)</th>
            </tr>
    """
    
    for name, stats in metrics.items():
        bb100 = stats['bb_per_100']
        ci = stats['bb_per_100_ci']
        vpip = stats['behavior']['vpip']['rate']
        pfr = stats['behavior']['pfr']['rate']
        decision_time = stats['behavior']['decision_time_ms']['mean']
        
        html += f"""
            <tr>
                <td>{name}</td>
                <td>{bb100:.2f}</td>
                <td>[{ci[0]:.2f}, {ci[1]:.2f}]</td>
                <td>{vpip:.1%}</td>
                <td>{pfr:.1%}</td>
                <td>{decision_time:.0f}</td>
            </tr>
        """
    
    html += """
        </table>
    </body>
    </html>
    """
    
    with open(output_file, 'w') as f:
        f.write(html)

# ä½¿ç”¨
generate_report(
    'artifacts/my_experiment/metrics/metrics.json',
    'analysis_report.html'
)
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### æ‰¹é‡å®éªŒ

```bash
# ä½¿ç”¨è„šæœ¬è¿è¡Œå¤šä¸ªå®éªŒ
python scripts/run_series.py
```

åˆ›å»ºæ‰¹é‡å®éªŒè„šæœ¬ï¼š

```python
# batch_experiments.py
import subprocess
import os

experiments = [
    {
        'name': 'gpt5_vs_random',
        'config': 'configs/dev_hu.yaml',
        'agent': 'green_agent_benchmark.agents.gpt5_agent:GPT5Agent',
        'agent_name': 'GPT5'
    },
    {
        'name': 'gpt5_vs_tag', 
        'config': 'configs/dev_hu.yaml',
        'agent': 'green_agent_benchmark.agents.gpt5_agent:GPT5Agent',
        'agent_name': 'GPT5'
    }
]

for exp in experiments:
    output_dir = f"artifacts/{exp['name']}"
    cmd = [
        'python', '-m', 'green_agent_benchmark.cli',
        '--config', exp['config'],
        '--agent', exp['agent'],
        '--agent-name', exp['agent_name'],
        '--output', output_dir
    ]
    
    print(f"è¿è¡Œå®éªŒ: {exp['name']}")
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        print(f"âœ… {exp['name']} å®Œæˆ")
    else:
        print(f"âŒ {exp['name']} å¤±è´¥: {result.stderr}")
```

### è‡ªå®šä¹‰æŒ‡æ ‡

æ‰©å±• `metrics.py` æ·»åŠ æ–°æŒ‡æ ‡ï¼š

```python
def calculate_custom_metrics(hand_records):
    """è®¡ç®—è‡ªå®šä¹‰æŒ‡æ ‡"""
    metrics = {}
    
    # è®¡ç®—æœ€å¤§å›æ’¤
    deltas = [r['delta'] for r in hand_records]
    cumulative = np.cumsum(deltas)
    running_max = np.maximum.accumulate(cumulative)
    drawdown = running_max - cumulative
    metrics['max_drawdown'] = float(np.max(drawdown))
    
    # è®¡ç®—å¤æ™®æ¯”ç‡
    if len(deltas) > 1:
        returns = np.array(deltas)
        metrics['sharpe_ratio'] = float(np.mean(returns) / np.std(returns))
    
    # è®¡ç®—è¿èƒœ/è¿è´¥
    win_streak = 0
    lose_streak = 0
    current_win_streak = 0
    current_lose_streak = 0
    
    for delta in deltas:
        if delta > 0:
            current_win_streak += 1
            current_lose_streak = 0
            win_streak = max(win_streak, current_win_streak)
        elif delta < 0:
            current_lose_streak += 1
            current_win_streak = 0
            lose_streak = max(lose_streak, current_lose_streak)
    
    metrics['max_win_streak'] = win_streak
    metrics['max_lose_streak'] = lose_streak
    
    return metrics
```

### å¤šè¿›ç¨‹å®éªŒ

```python
# parallel_runner.py
from concurrent.futures import ProcessPoolExecutor
import subprocess

def run_experiment(config):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    cmd = [
        'python', '-m', 'green_agent_benchmark.cli',
        '--config', config['config_file'],
        '--agent', config['agent'],
        '--output', config['output_dir']
    ]
    return subprocess.run(cmd, capture_output=True, text=True)

def run_parallel_experiments(experiments, max_workers=4):
    """å¹¶è¡Œè¿è¡Œå¤šä¸ªå®éªŒ"""
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(run_experiment, exp): exp 
                  for exp in experiments}
        
        for future in futures:
            exp = futures[future]
            try:
                result = future.result()
                print(f"âœ… {exp['name']} å®Œæˆ")
            except Exception as e:
                print(f"âŒ {exp['name']} å¤±è´¥: {e}")
```

### Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["python", "leaderboard/server.py"]
```

```bash
# æ„å»ºå¹¶è¿è¡Œ
docker build -t green-agent-benchmark .
docker run -p 8000:8000 -v $(pwd)/artifacts:/app/artifacts green-agent-benchmark
```

---

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å®‰è£…é—®é¢˜

**é—®é¢˜**: `ModuleNotFoundError: No module named 'green_agent_benchmark'`

**è§£å†³**:
```bash
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
pwd  # åº”è¯¥æ˜¾ç¤º .../Project1_Texas

# é‡æ–°å®‰è£…
pip install -e .

# æˆ–è€…è®¾ç½®PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

#### 2. APIå¯†é’¥é—®é¢˜

**é—®é¢˜**: `OpenAI API error: Invalid API key`

**è§£å†³**:
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# é‡æ–°è®¾ç½®
export OPENAI_API_KEY=sk-your-actual-key

# æˆ–åˆ›å»º.envæ–‡ä»¶
echo "OPENAI_API_KEY=sk-your-actual-key" > .env
```

#### 3. å†…å­˜ä¸è¶³

**é—®é¢˜**: 6-Maxå®éªŒå ç”¨å†…å­˜è¿‡å¤š

**è§£å†³**:
```yaml
# å‡å°‘å®éªŒè§„æ¨¡ (configs/dev_6max.yaml)
hands_per_replica: 50  # ä»200å‡å°‘åˆ°50
seeds: [201]           # åªç”¨1ä¸ªç§å­
```

#### 4. è¶…æ—¶é—®é¢˜

**é—®é¢˜**: LLMä»£ç†å“åº”è¶…æ—¶

**è§£å†³**:
```yaml
# å¢åŠ è¶…æ—¶æ—¶é—´ (configæ–‡ä»¶)
time_per_decision_ms: 120000  # 2åˆ†é’Ÿ

# æˆ–åœ¨ä»£ç†ä¸­è®¾ç½®
class MyAgent:
    def act(self, request):
        if request.timebank_ms < 5000:  # æ—¶é—´ä¸è¶³æ—¶å¿«é€Ÿå†³ç­–
            return ActionResponse(action="fold")
        # æ­£å¸¸å†³ç­–é€»è¾‘...
```

#### 5. æ’è¡Œæ¦œæ˜¾ç¤ºé—®é¢˜

**é—®é¢˜**: æ’è¡Œæ¦œæ˜¾ç¤º"No data available"

**è§£å†³**:
```bash
# 1. æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls leaderboard/data/
cat leaderboard/data/leaderboard.json

# 2. é‡æ–°ç”Ÿæˆ
python leaderboard/leaderboard_generator.py

# 3. æ£€æŸ¥artifactsç›®å½•
ls artifacts/*/metrics/metrics.json
```

#### 6. ç«¯å£å ç”¨

**é—®é¢˜**: `OSError: [Errno 48] Address already in use`

**è§£å†³**:
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£8000çš„è¿›ç¨‹
lsof -i :8000

# ç»ˆæ­¢è¿›ç¨‹
kill -9 <PID>

# æˆ–ä½¿ç”¨ä¸åŒç«¯å£
python leaderboard/server.py --port 8001
```

### æ—¥å¿—è°ƒè¯•

#### å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
# è®¾ç½®æ—¥å¿—çº§åˆ«
export LOG_LEVEL=DEBUG

# è¿è¡Œå®éªŒ
python -m green_agent_benchmark.cli \
  --config configs/dev_hu.yaml \
  --agent baseline:random-hu \
  --output artifacts/debug_run \
  --verbose
```

#### æ£€æŸ¥æ¸¸æˆæ—¥å¿—

```bash
# æŸ¥çœ‹æœ€è¿‘çš„æ‰‹ç‰Œæ—¥å¿—
tail -n 50 artifacts/my_experiment/logs/hu/random-hu/seed101_rep0.ndjson

# è§£æJSONæ ¼å¼
cat artifacts/my_experiment/logs/hu/random-hu/seed101_rep0.ndjson | \
  python -m json.tool | less
```

#### æ£€æŸ¥æŒ‡æ ‡å¼‚å¸¸

```python
# debug_metrics.py
import json

with open('artifacts/my_experiment/metrics/metrics.json') as f:
    metrics = json.load(f)

for agent, stats in metrics.items():
    bb_100 = stats['bb_per_100']
    
    # æ£€æŸ¥å¼‚å¸¸å€¼
    if abs(bb_100) > 1000:
        print(f"âš ï¸ {agent} BB/100å¼‚å¸¸: {bb_100}")
    
    # æ£€æŸ¥ç½®ä¿¡åŒºé—´
    ci_low, ci_high = stats['bb_per_100_ci']
    if ci_high - ci_low > 200:
        print(f"âš ï¸ {agent} ç½®ä¿¡åŒºé—´è¿‡å®½: [{ci_low:.2f}, {ci_high:.2f}]")
```

### æ€§èƒ½ä¼˜åŒ–

#### 1. å‡å°‘APIè°ƒç”¨å»¶è¿Ÿ

```python
class OptimizedLLMAgent:
    def __init__(self):
        self.decision_cache = {}  # ç¼“å­˜ç›¸ä¼¼æƒ…å†µçš„å†³ç­–
    
    def act(self, request):
        # ç”ŸæˆçŠ¶æ€å“ˆå¸Œ
        state_hash = self._hash_state(request)
        
        # æ£€æŸ¥ç¼“å­˜
        if state_hash in self.decision_cache:
            return self.decision_cache[state_hash]
        
        # è°ƒç”¨LLM
        response = self._call_llm(request)
        
        # ç¼“å­˜ç»“æœ
        self.decision_cache[state_hash] = response
        return response
```

#### 2. å¹¶è¡Œè¿è¡Œå®éªŒ

```bash
# åŒæ—¶è¿è¡Œå¤šä¸ªç‹¬ç«‹å®éªŒ
python -m green_agent_benchmark.cli --config configs/exp1.yaml --output artifacts/exp1 &
python -m green_agent_benchmark.cli --config configs/exp2.yaml --output artifacts/exp2 &
python -m green_agent_benchmark.cli --config configs/exp3.yaml --output artifacts/exp3 &
wait  # ç­‰å¾…æ‰€æœ‰åå°ä»»åŠ¡å®Œæˆ
```

#### 3. ä¼˜åŒ–é…ç½®

```yaml
# å¼€å‘æœŸé—´ä½¿ç”¨å°è§„æ¨¡é…ç½®
seeds: [101, 102]        # åªç”¨2ä¸ªç§å­
hands_per_seed: 100      # å‡å°‘æ‰‹æ•°
hands_per_replica: 50    # 6-maxæ¨¡å¼

# ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å®Œæ•´é…ç½®
seeds: [101, 102, 103, 104, 105, 106, 107, 108, 109, 110]
hands_per_seed: 1000
hands_per_replica: 300
```

---

## ğŸ“š æ›´å¤šèµ„æº

### æ–‡æ¡£é“¾æ¥
- [æ¶æ„æ–‡æ¡£](docs/ARCHITECTURE.md)
- [APIå‚è€ƒ](docs/API_REFERENCE.md)
- [AgentBeatsé›†æˆ](docs/AGENTBEATS.md)

### ç¤¾åŒºæ”¯æŒ
- GitHub Issues: æŠ¥å‘Šbugå’ŒåŠŸèƒ½è¯·æ±‚
- Discussions: æŠ€æœ¯è®¨è®ºå’Œç»éªŒåˆ†äº«

### ç›¸å…³è®ºæ–‡
- "Green Agent Benchmark: A Framework for Evaluating LLMs in Strategic Environments"
- "Variance Reduction Techniques in Multi-Agent Poker Evaluation"

---

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

1. **æ‰©å±•æ¸¸æˆå˜ä½“**: PLO (Pot-Limit Omaha)æ”¯æŒ
2. **é”¦æ ‡èµ›æ¨¡å¼**: MTT (Multi-Table Tournament)
3. **æ›´å¤šLLMé›†æˆ**: Claude, GPT-4ç­‰
4. **é«˜çº§åˆ†æ**: å¯¹æ‰‹å»ºæ¨¡ã€å¯è§£é‡Šæ€§åˆ†æ
5. **äº‘ç«¯éƒ¨ç½²**: AWS/GCPè‡ªåŠ¨åŒ–éƒ¨ç½²

---

**ç¥ä½ åœ¨Green Agent Benchmarkçš„æ¢ç´¢ä¹‹æ—…ä¸­æ”¶è·æ»¡æ»¡ï¼** ğŸ°â™ ï¸â™¥ï¸â™£ï¸â™¦ï¸

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·å‚è€ƒæ•…éšœæ’é™¤ç« èŠ‚æˆ–æäº¤GitHub Issueã€‚